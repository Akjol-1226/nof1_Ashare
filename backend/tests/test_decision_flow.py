#!/usr/bin/env python3
"""
æµ‹è¯•ç«¯åˆ°ç«¯AIå†³ç­–æµç¨‹
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database import get_db_session
from models.models import AI
from data_service.akshare_client import AKShareClient
from ai_service.prompt_builder import PromptBuilder
from ai_service.decision_parser import DecisionParser
from ai_service.llm_adapters.adapter_factory import LLMAdapterFactory

def test_decision_flow():
    """æµ‹è¯•å®Œæ•´çš„å†³ç­–æµç¨‹"""
    print("=" * 60)
    print("  æµ‹è¯•ç«¯åˆ°ç«¯AIå†³ç­–æµç¨‹")
    print("=" * 60)

    # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
    print("\n1. æ£€æŸ¥ç¯å¢ƒå˜é‡...")
    env_vars = ['DASHSCOPE_API_KEY', 'MOONSHOT_API_KEY', 'DEEPSEEK_API_KEY']
    missing_vars = []

    for var in env_vars:
        if not os.getenv(var):
            missing_vars.append(var)

    if missing_vars:
        print(f"âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        print("è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç„¶åå†è¿è¡Œæµ‹è¯•")
        return
    else:
        print("âœ… æ‰€æœ‰ç¯å¢ƒå˜é‡å·²è®¾ç½®")

    # 2. æ£€æŸ¥æ•°æ®åº“
    print("\n2. æ£€æŸ¥æ•°æ®åº“...")
    with get_db_session() as db:
        ais = db.query(AI).filter(AI.is_active == True).all()
        if not ais:
            print("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰æ¿€æ´»çš„AI")
            print("è¯·å…ˆè¿è¡Œ: python3 backend/scripts/import_ais.py")
            return

        print(f"âœ… æ‰¾åˆ° {len(ais)} ä¸ªæ¿€æ´»çš„AI:")
        for ai in ais:
            print(f"   â€¢ {ai.name} ({ai.model_type})")

    # 3. æµ‹è¯•æ•°æ®è·å–
    print("\n3. æµ‹è¯•å®æ—¶è¡Œæƒ…è·å–...")
    try:
        client = AKShareClient()
        quotes = client.get_realtime_quotes()
        if not quotes:
            print("âŒ æ— æ³•è·å–å®æ—¶è¡Œæƒ…")
            return

        print(f"âœ… è·å–åˆ° {len(quotes)} åªè‚¡ç¥¨çš„è¡Œæƒ…æ•°æ®")
        for i, q in enumerate(quotes[:3]):  # åªæ˜¾ç¤ºå‰3åª
            print(f"   â€¢ {q.code} {q.name}: Â¥{q.price:.2f} ({q.change_percent:+.2f}%)")

    except Exception as e:
        print(f"âŒ è¡Œæƒ…è·å–å¤±è´¥: {str(e)}")
        return

    # 4. æµ‹è¯•é€‚é…å™¨åˆ›å»º
    print("\n4. æµ‹è¯•LLMé€‚é…å™¨...")
    for ai in ais:
        try:
            adapter = LLMAdapterFactory.create_adapter(ai.name)
            if adapter:
                print(f"âœ… {ai.name} é€‚é…å™¨åˆ›å»ºæˆåŠŸ")
            else:
                print(f"âŒ {ai.name} é€‚é…å™¨åˆ›å»ºå¤±è´¥")
                return
        except Exception as e:
            print(f"âŒ {ai.name} é€‚é…å™¨åˆ›å»ºå¼‚å¸¸: {str(e)}")
            return

    # 5. æµ‹è¯•Promptæ„å»º
    print("\n5. æµ‹è¯•Promptæ„å»º...")
    try:
        builder = PromptBuilder()
        parser = DecisionParser()

        # é€‰æ‹©ç¬¬ä¸€ä¸ªAIè¿›è¡Œæµ‹è¯•
        test_ai = ais[0]
        positions = []  # ç©ºæŒä»“

        user_prompt = builder.build_user_prompt(test_ai, quotes, positions)
        full_prompt = builder.build_full_prompt(test_ai.system_prompt, user_prompt)

        print(f"âœ… {test_ai.name} Promptæ„å»ºæˆåŠŸ")
        print(f"   System Prompté•¿åº¦: {len(full_prompt['system'])} å­—ç¬¦")
        print(f"   User Prompté•¿åº¦: {len(full_prompt['user'])} å­—ç¬¦")

    except Exception as e:
        print(f"âŒ Promptæ„å»ºå¤±è´¥: {str(e)}")
        return

    # 6. æµ‹è¯•å†³ç­–è§£æ
    print("\n6. æµ‹è¯•å†³ç­–è§£æ...")

    # æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„å†³ç­–å“åº”
    mock_response = '''{
  "reasoning": "æµ‹è¯•å†³ç­–æµç¨‹ï¼Œæš‚æ—¶è§‚æœ›",
  "actions": []
}'''

    try:
        parse_result = parser.parse(mock_response)
        if parse_result["success"]:
            print("âœ… å†³ç­–è§£ææˆåŠŸ")
            print(f"   æ¨ç†: {parse_result['reasoning']}")
            print(f"   æ“ä½œæ•°é‡: {len(parse_result['actions'])}")
        else:
            print(f"âŒ å†³ç­–è§£æå¤±è´¥: {parse_result['error']}")
            return

    except Exception as e:
        print(f"âŒ å†³ç­–è§£æå¼‚å¸¸: {str(e)}")
        return

    # 7. æµ‹è¯•LLMè°ƒç”¨ï¼ˆå¯é€‰ï¼‰
    print("\n7. æµ‹è¯•LLMè°ƒç”¨ï¼ˆå¯é€‰ï¼‰...")

    test_llm = input("æ˜¯å¦æµ‹è¯•çœŸå®çš„LLMè°ƒç”¨? (y/n): ").strip().lower()
    if test_llm == 'y':
        try:
            adapter = LLMAdapterFactory.create_adapter(test_ai.name)
            if adapter:
                # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹ï¼Œè¯·ç®€çŸ­å›å¤"},
                    {"role": "user", "content": "Hello"}
                ]

                result = adapter.call_api(messages, timeout=10)
                if result["success"]:
                    print("âœ… LLMè°ƒç”¨æˆåŠŸ")
                    print(f"   å“åº”: {result['response'][:100]}...")
                    print(f"   å»¶è¿Ÿ: {result['latency_ms']}ms")
                else:
                    print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {result['error']}")
            else:
                print("âŒ æ— æ³•åˆ›å»ºé€‚é…å™¨")

        except Exception as e:
            print(f"âŒ LLMè°ƒç”¨å¼‚å¸¸: {str(e)}")

    # 8. æ€»ç»“
    print("\n" + "=" * 60)
    print("  æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    print("âœ… ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡")
    print("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
    print("âœ… å®æ—¶è¡Œæƒ…è·å–æˆåŠŸ")
    print("âœ… LLMé€‚é…å™¨åˆ›å»ºæˆåŠŸ")
    print("âœ… Promptæ„å»ºæ­£å¸¸")
    print("âœ… å†³ç­–è§£æå·¥ä½œæ­£å¸¸")
    print()
    print("ğŸ‰ ç«¯åˆ°ç«¯å†³ç­–æµç¨‹æµ‹è¯•é€šè¿‡ï¼")
    print()
    print("ç°åœ¨å¯ä»¥å¯åŠ¨AIäº¤æ˜“ç³»ç»Ÿäº†:")
    print("  cd backend")
    print("  python3 main.py")
    print("=" * 60)

if __name__ == "__main__":
    try:
        test_decision_flow()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æµ‹è¯•ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
